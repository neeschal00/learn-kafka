{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.types import StringType, StructType, StructField, FloatType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, udf\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Twitter sentiment analysis\").config(\"spark.jars.packages\",\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2\").getOrCreate()\n",
    "\n",
    "df = spark.readStream .format(\"kafka\").option(\"kafka.bootstrap.servers\", \"172.16.5.4:9092\") .option(\"subscribe\", \"twitter\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySchema = StructType([StructField(\"text\", StringType(), True)])\n",
    "values = df.select(from_json(df.value.cast(\"string\"), mySchema).alias(\"tweet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTweet(tweet: str) -> str:\n",
    "    tweet = re.sub(r'http\\S+', '', str(tweet))\n",
    "    tweet = re.sub(r'bit.ly/\\S+', '', str(tweet))\n",
    "    tweet = tweet.strip('[link]')\n",
    "\n",
    "    # remove users\n",
    "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', str(tweet))\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', str(tweet))\n",
    "\n",
    "    # remove puntuation\n",
    "    my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@â'\n",
    "    tweet = re.sub('[' + my_punctuation + ']+', ' ', str(tweet))\n",
    "\n",
    "    # remove number\n",
    "    tweet = re.sub('([0-9]+)', '', str(tweet))\n",
    "\n",
    "    # remove hashtag\n",
    "    tweet = re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)', '', str(tweet))\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = values.select(\"tweet.*\")\n",
    "clean_tweets = F.udf(cleanTweet, StringType())\n",
    "raw_tweets = df1.withColumn('processed_text', clean_tweets(col(\"text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the subjectifvity\n",
    "def getSubjectivity(tweet: str) -> float:\n",
    "    return TextBlob(tweet).sentiment.subjectivity\n",
    "\n",
    "\n",
    "# Create a function to get the polarity\n",
    "def getPolarity(tweet: str) -> float:\n",
    "    return TextBlob(tweet).sentiment.polarity\n",
    "\n",
    "\n",
    "def getSentiment(polarityValue: int) -> str:\n",
    "    if polarityValue < 0:\n",
    "        return 'Negative'\n",
    "    elif polarityValue == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity = F.udf(getSubjectivity, FloatType())\n",
    "polarity = F.udf(getPolarity, FloatType())\n",
    "sentiment = F.udf(getSentiment, StringType())\n",
    "\n",
    "subjectivity_tweets = raw_tweets.withColumn('subjectivity', subjectivity(col(\"processed_text\")))\n",
    "polarity_tweets = subjectivity_tweets.withColumn(\"polarity\", polarity(col(\"processed_text\")))\n",
    "sentiment_tweets = polarity_tweets.withColumn(\"sentiment\", sentiment(col(\"polarity\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"TwitterSentimentAnalysis\")\\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "    df = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "        .option(\"subscribe\", \"twitter\") \\\n",
    "        .load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bb95c8546605f065b4866bff5f8a9db09fbeee13678af8fe41199dd21e1babb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
